{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of tests for minimal functionality for \"modin in the cloud\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the `ParseOutputPytest` modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ParseOutputPytest import ParseOutputPytest\n",
    "\n",
    "pop = ParseOutputPytest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting environment variables and flags for pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_variables = 'set MODIN_EXPERIMENTAL=1 && set MODIN_ENGINE=Python'\n",
    "pytest_args = '--simulate-cloud=normal'\n",
    "\n",
    "path_dir = 'C:\\\\prog\\\\modin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will indicate how many last lines in the errors to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_line = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a list of errors for test_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will get json, where we will take the data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start collecting information on the specified test\n",
    "path_test_io = 'modin\\\\pandas\\\\test\\\\test_io.py'\n",
    "# file_name_test_io = pop.start_test(path_dir, path_test_io, environment_variables=environment_variables, args_pytest=pytest_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will get grouped errors with a list of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_test_io = \"C:\\\\prog\\\\modin\\\\test_analytics\\\\json_analytics_from_test\\\\modin_pandas_test_test_io.json\"\n",
    "\n",
    "full_dict_test_io = pop.get_dict_name_with_error_text(file_name_test_io)\n",
    "groupby_error_test_io = pop.get_dict_error_with_list_test(full_dict_test_io, number_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's output nice statistics on test_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors:   86\n",
      "Unique errors:  22\n"
     ]
    }
   ],
   "source": [
    "#### Output the number of unique errors \n",
    "print(\"Total errors:  \", len(full_dict_test_io))\n",
    "print(\"Unique errors: \", len(groupby_error_test_io))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a list of errors for test_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will get json, where we will take the data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_series = 'modin\\\\pandas\\\\test\\\\test_series.py'\n",
    "# file_name_test_series = pop.start_test(path_dir, path_test_series, environment_variables=environment_variables, args_pytest=pytest_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will get grouped errors with a list of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_test_series = 'C:\\\\prog\\\\modin\\\\test_analytics\\\\json_analytics_from_test\\\\modin_pandas_test_test_series.json'\n",
    "\n",
    "full_dict_test_series = pop.get_dict_name_with_error_text(file_name_test_series)\n",
    "groupby_error_test_series = pop.get_dict_error_with_list_test(full_dict_test_series, number_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's output nice statistics on test_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors:   1844\n",
      "Unique errors:  90\n"
     ]
    }
   ],
   "source": [
    "#### Output the number of unique errors \n",
    "print(\"Total errors:  \", len(full_dict_test_series))\n",
    "print(\"Unique errors: \", len(groupby_error_test_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a list of errors for test_map_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will get json, where we will take the data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_map_metadata = 'modin\\\\pandas\\\\test\\dataframe\\\\test_map_metadata.py'\n",
    "# file_name_test_map_metadata = pop.start_test(path_dir, path_test_map_metadata, environment_variables=environment_variables, args_pytest=pytest_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will get grouped errors with a list of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_test_map_metadata = 'C:\\\\prog\\\\modin\\\\test_analytics\\\\json_analytics_from_test\\\\modin_pandas_test_dataframe_test_map_metadata.json'\n",
    "\n",
    "full_dict_test_map_metadata = pop.get_dict_name_with_error_text(file_name_test_map_metadata)\n",
    "groupby_error_test_map_metadata = pop.get_dict_error_with_list_test(full_dict_test_map_metadata, number_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's output nice statistics on test_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors:   136\n",
      "Unique errors:  30\n"
     ]
    }
   ],
   "source": [
    "#### Output the number of unique errors \n",
    "print(\"Total errors:  \", len(full_dict_test_map_metadata))\n",
    "print(\"Unique errors: \", len(groupby_error_test_map_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's combine the errors from all 3 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dict_error = {**full_dict_test_io, **full_dict_test_series, **full_dict_test_map_metadata}\n",
    "full_dict_groupby = pop.get_dict_error_with_list_test(full_dict_error, number_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will display beautiful statistics for all 3 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors:   2066\n",
      "Unique errors:  131\n"
     ]
    }
   ],
   "source": [
    "#### Output the number of unique errors\n",
    "print(\"Total errors:  \", len(full_dict_test_map_metadata) + len(full_dict_test_io) + len(full_dict_test_series))\n",
    "print(\"Unique errors: \", len(full_dict_groupby))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------\n",
      "C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\pandas\\_testing.py:744: in _check_types\n",
      "    assert_attr_equal(\"dtype\", left, right, obj=obj)\n",
      "C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\pandas\\core\\dtypes\\inference.py:68: in is_number\n",
      "    return isinstance(obj, (Number, np.number))\n",
      "C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\abc.py:98: in __instancecheck__\n",
      "    return _abc_instancecheck(cls, instance)\n",
      "C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\abc.py:102: in __subclasscheck__\n",
      "    return _abc_subclasscheck(cls, subclass)\n",
      "E   TypeError: issubclass() arg 1 must be a class \n",
      "\n",
      "Occurs in 1055 tests.\n",
      "     modin/pandas/test/test_series.py::test_callable_key_in_getitem[int_data]\n",
      "     modin/pandas/test/test_series.py::test_callable_key_in_getitem[float_nan_data]\n",
      "     modin/pandas/test/test_series.py::test_T[int_data]\n",
      "And also in 1052 tests.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "E   ========= Remote Traceback (1) =========\n",
      "E   Traceback (most recent call last):\n",
      "E     File \"C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\rpyc\\core\\protocol.py\", line 320, in _dispatch_request\n",
      "E       res = self._HANDLERS[handler](self, *args)\n",
      "E     File \"C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\rpyc\\core\\protocol.py\", line 593, in _handle_call\n",
      "E       return obj(*args, **dict(kwargs))\n",
      "E   TypeError: can only be called with ndarray object \n",
      "\n",
      "Occurs in 264 tests.\n",
      "     modin/pandas/test/test_series.py::test___getitem__[int_data]\n",
      "     modin/pandas/test/test_series.py::test_agg[sum-int_data]\n",
      "     modin/pandas/test/test_series.py::test_aggregate[sum-int_data]\n",
      "And also in 261 tests.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "E   ========= Remote Traceback (1) =========\n",
      "E   Traceback (most recent call last):\n",
      "E     File \"C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\rpyc\\core\\protocol.py\", line 320, in _dispatch_request\n",
      "E       res = self._HANDLERS[handler](self, *args)\n",
      "E     File \"C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\rpyc\\core\\protocol.py\", line 593, in _handle_call\n",
      "E       return obj(*args, **dict(kwargs))\n",
      "E     File \"C:\\prog\\modin\\modin\\experimental\\cloud\\rpyc_proxy.py\", line 38, in _pickled_array\n",
      "E       return pickle.dumps(obj.__array__())\n",
      "E   AttributeError: 'slice' object has no attribute '__array__' \n",
      "\n",
      "Occurs in 192 tests.\n",
      "     modin/pandas/test/test_series.py::test___and__[float_nan_data]\n",
      "     modin/pandas/test/test_series.py::test___or__[float_nan_data]\n",
      "     modin/pandas/test/test_series.py::test___repr__[int_data-dt_index_true-Dates]\n",
      "And also in 189 tests.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "modin\\pandas\\test\\dataframe\\test_map_metadata.py:728: in test_drop_duplicates\n",
      "    df_equals(\n",
      "modin\\pandas\\test\\utils.py:527: in df_equals\n",
      "    assert_frame_equal(\n",
      "E   AssertionError \n",
      "\n",
      "Occurs in 47 tests.\n",
      "     modin/pandas/test/dataframe/test_map_metadata.py::test_drop_duplicates[None-last-no_duplicates]\n",
      "     modin/pandas/test/dataframe/test_map_metadata.py::test_drop_duplicates[None-last-all_duplicates]\n",
      "     modin/pandas/test/dataframe/test_map_metadata.py::test_drop_duplicates[None-last-some_duplicates]\n",
      "And also in 44 tests.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "======= Remote Traceback =======\n",
      " ... \n",
      "E       mgr = init_dict({data.name: data}, index, columns, dtype=dtype)\n",
      "E     File \"C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 287, in init_dict\n",
      "E       return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)\n",
      "E     File \"C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 80, in arrays_to_mgr\n",
      "E       index = extract_index(arrays)\n",
      "E     File \"C:\\Users\\alozovsk\\Anaconda3\\envs\\modin\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 382, in extract_index\n",
      "E       indexes.append(val.index)\n",
      "E     File \"pandas\\_libs\\properties.pyx\", line 62, in pandas._libs.properties.AxisProperty.__get__\n",
      "E   TypeError: Expected list, got type \n",
      "\n",
      "Occurs in 43 tests.\n",
      "     modin/pandas/test/test_io.py::TestCsv::test_series_to_csv\n",
      "     modin/pandas/test/test_series.py::test_fillna[None-None-int_data]\n",
      "     modin/pandas/test/test_series.py::test_fillna[None-None-float_nan_data]\n",
      "And also in 40 tests.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will get the top 5 errors by the frequency of occurrence in the tests\n",
    "count_test_print = 5\n",
    "\n",
    "list_error_count_test = []\n",
    "for text_error, list_test in full_dict_groupby.items():\n",
    "    list_error_count_test.append((text_error, len(list_test)))\n",
    "\n",
    "sorted_list_error = sorted(list_error_count_test, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# If the number of tests in the array is less than this number, \n",
    "#   then we will output all the tests\n",
    "number_tests_print = 5 \n",
    "\n",
    "# If the number of tests is greater than the previous number, \n",
    "#   then we will output the following number of tests\n",
    "number_tests_print_part = 3\n",
    "\n",
    "for text_error, _ in sorted_list_error[:count_test_print]:\n",
    "    list_test = full_dict_groupby[text_error]\n",
    "\n",
    "    print('---------------------------------------------------------------------------------------------------------------------')\n",
    "    print(text_error, '\\n')\n",
    "    print(f'Occurs in {len(list_test)} tests.')\n",
    "    if len(list_test) <= number_tests_print:\n",
    "        for test in list_test:\n",
    "            print('    ', test)\n",
    "    else:\n",
    "        for i in range(number_tests_print_part):\n",
    "            print('    ', list_test[i])\n",
    "        print(f'And also in {len(list_test) - number_tests_print_part} tests.')\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------------------')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0164592e50740c884f3c212fdfd09eb575d2d867372f70a01aaaef73514311d0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
